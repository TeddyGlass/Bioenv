{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import model_from_json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_cutoff(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def evaluate_clf(y_true, y_pred, cutoff):\n",
    "    pred_label = (y_pred >= cutoff) * 1\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred_label).ravel()\n",
    "    accuracy = accuracy_score(y_true, pred_label)\n",
    "    balanced_accuracy = (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "    mcc = matthews_corrcoef(y_true, pred_label)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'auc': [auc],\n",
    "        'acc': [accuracy],\n",
    "        'sen': [sensitivity],\n",
    "        'spe': [specificity],\n",
    "        'bac': [balanced_accuracy],\n",
    "        'mcc': [mcc],\n",
    "        'cutoff': [cutoff]\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def load_lgb(path):\n",
    "    if 'LGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_rf(path):\n",
    "    if 'RandomForest' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_svm(path):\n",
    "    if 'SVM' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb(path):\n",
    "    if 'XGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_nn(path_json, path_h5, path_transformer):\n",
    "    if 'NN' in path_json:\n",
    "        with open(path_json, 'r') as f:\n",
    "            json_string = f.read()\n",
    "        model = model_from_json(json_string)\n",
    "        model.load_weights(path_h5)\n",
    "        if os.path.exists(path_transformer):\n",
    "            with open(path_transformer, 'rb') as f:\n",
    "                transformer = pickle.load(f)\n",
    "        else:\n",
    "            transformer = None\n",
    "        return model, transformer\n",
    "\n",
    "\n",
    "def sort_preds(PREDS, IDXES):\n",
    "    va_idxes = np.concatenate(IDXES)\n",
    "    order = np.argsort(va_idxes)\n",
    "    va_preds = np.concatenate(PREDS)\n",
    "    return va_preds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurosaki/Document/Research/PJ0/Repository/Bioenv/src\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "print(root)\n",
    "\n",
    "n_splits_ncv = 5\n",
    "seed_ncv = 1712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPPIBERT\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "       auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.98096  0.942753  0.926419  0.948554  0.937487  0.856277  0.244995\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.934172  0.896211  0.843279  0.915012  0.879146  0.739729  0.260835\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SVMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.934172  0.896211  0.843279  0.915012  0.879146  0.739729  0.260835\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 11:34:29.075489: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 11:34:37.362229: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-15 11:34:37.362625: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2198655000 Hz\n"
     ]
    }
   ],
   "source": [
    "f_names = [\n",
    "        'DeepPPIEmbedd_BERT_BFD.csv',\n",
    "        'DeepPPIEmbedd_Albert_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_FT.csv'\n",
    "    ]\n",
    "data_names = [\n",
    "    'DeepPPIBERT',\n",
    "        'DeepPPIAlbert',\n",
    "        'DeepPPIT5',\n",
    "        'DeepPPIT5FT'\n",
    "    ]\n",
    "\n",
    "results = {\n",
    "    data:{\n",
    "        i:{\n",
    "        'LGBMClassifier':None,\n",
    "        'RandomForestClassifier':None,\n",
    "        'NNClassifier':None\n",
    "        }\n",
    "        for i in range(5)\n",
    "        }\n",
    "        for data in data_names\n",
    "}\n",
    "\n",
    "for f_name, data_name in zip(f_names, data_names):\n",
    "     # load core data set for PPI classification\n",
    "    df = pd.read_csv('../data/DeepPPI/DeepPPIAll.csv')\n",
    "    protein_a = np.array(df['proteinA'])\n",
    "    protein_b = np.array(df['proteinB'])\n",
    "    y = np.array(df['interaction'])\n",
    "\n",
    "    # load features\n",
    "    df_feature = pd.read_csv(f'../data/DeepPPI/{f_name}')\n",
    "    # pre-processing of protein features\n",
    "    feature_dict = {\n",
    "        Id: np.array(df_feature[df_feature.iloc[:,0]==Id].iloc[:,1:])\n",
    "        for Id in df_feature.iloc[:,0].tolist()\n",
    "    }\n",
    "    feature_a, feature_b = [], []\n",
    "    for a, b in zip(protein_a, protein_b):\n",
    "        feature_a.append(feature_dict[a])\n",
    "        feature_b.append(feature_dict[b])\n",
    "    X_a, X_b = np.concatenate(feature_a), np.concatenate(feature_b)\n",
    "    X = np.concatenate([X_a, X_b], axis=1)\n",
    "    print(data_name)\n",
    "    print('X_shape', X.shape)\n",
    "    print('y_shape', y.shape)\n",
    "    skf_outer = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True) \n",
    "    outer_idxes = list(skf_outer.split(X, y))\n",
    "\n",
    "    # evaluate ptrained model\n",
    "    for i, (inner_idx, te_idx) in enumerate(outer_idxes):\n",
    "        if i == 0:\n",
    "            print('*'*100)\n",
    "            print('fold', i)\n",
    "            for model_name in ['LGBMClassifier', 'RandomForestClassifier', 'NNClassifier']:\n",
    "                skf_inner = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True)\n",
    "                inner_idxes = list(skf_outer.split(X[inner_idx], y[inner_idx]))\n",
    "                print('-'*100)\n",
    "                print(model_name)\n",
    "                te_preds, cutoffs = [], []\n",
    "                for j, (tr_idx, va_idx) in enumerate(inner_idxes):\n",
    "                    if 'LGB' in model_name:\n",
    "                        model = load_lgb(f'../results/models/{data_name}/LGBMClassifier/LGBMClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                    elif 'RandomForest' in model_name:\n",
    "                        model = load_rf(f'../results/models/{data_name}/RandomForestClassifier/RandomForestClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx])[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx])[:,1]\n",
    "                    elif 'NN' in model_name:\n",
    "                        model, transformer = load_nn(\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_i{i}_architecture.json',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_trainedweight.h5',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_transformer.pkl'\n",
    "                            )\n",
    "                        va_pred = model.predict(transformer.transform(X[inner_idx][va_idx]))\n",
    "                        te_pred = model.predict(transformer.transform(X[te_idx]))\n",
    "                cutoff = roc_cutoff(y[inner_idx][va_idx], va_pred)\n",
    "                te_preds.append(te_pred)\n",
    "                cutoffs.append(cutoff)\n",
    "                te_pred_mean = np.mean(te_preds, axis=0)\n",
    "                metrics = evaluate_clf(y[te_idx], te_pred_mean, np.mean(cutoffs))\n",
    "                print(pd.DataFrame(metrics))\n",
    "                results[data_name][i][model_name] = pd.DataFrame(metrics)\n",
    "            print('*'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "for data_name in data_names:\n",
    "    result_dict = results[data_name][0]\n",
    "    df_result = pd.concat([v for v in result_dict.values()])\n",
    "    df_result['data'] = data_name\n",
    "    df_result.index = list(result_dict.keys())[-len(df_result):]\n",
    "    df_results.append(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>sen</th>\n",
       "      <th>spe</th>\n",
       "      <th>bac</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.916598</td>\n",
       "      <td>0.864529</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.893728</td>\n",
       "      <td>0.857806</td>\n",
       "      <td>0.718339</td>\n",
       "      <td>0.317998</td>\n",
       "      <td>DeepLocBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.885594</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>0.659033</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.799029</td>\n",
       "      <td>0.638578</td>\n",
       "      <td>0.472167</td>\n",
       "      <td>DeepLocBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.839267</td>\n",
       "      <td>0.815926</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.836237</td>\n",
       "      <td>0.811248</td>\n",
       "      <td>0.620150</td>\n",
       "      <td>0.393979</td>\n",
       "      <td>DeepLocBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.915800</td>\n",
       "      <td>0.849018</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.844739</td>\n",
       "      <td>0.687880</td>\n",
       "      <td>0.351950</td>\n",
       "      <td>DeepLocBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.920991</td>\n",
       "      <td>0.844881</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.869338</td>\n",
       "      <td>0.839249</td>\n",
       "      <td>0.678498</td>\n",
       "      <td>0.291704</td>\n",
       "      <td>DeepLocAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.859625</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.648855</td>\n",
       "      <td>0.911150</td>\n",
       "      <td>0.780002</td>\n",
       "      <td>0.591402</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>DeepLocAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.494856</td>\n",
       "      <td>0.593588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.406519</td>\n",
       "      <td>DeepLocAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.925739</td>\n",
       "      <td>0.864529</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.886760</td>\n",
       "      <td>0.859410</td>\n",
       "      <td>0.719111</td>\n",
       "      <td>0.318228</td>\n",
       "      <td>DeepLocAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.936201</td>\n",
       "      <td>0.855222</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.850174</td>\n",
       "      <td>0.856385</td>\n",
       "      <td>0.705354</td>\n",
       "      <td>0.276454</td>\n",
       "      <td>DeepLocT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.903219</td>\n",
       "      <td>0.807653</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812704</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>0.349314</td>\n",
       "      <td>DeepLocT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.864701</td>\n",
       "      <td>0.830403</td>\n",
       "      <td>0.826972</td>\n",
       "      <td>0.832753</td>\n",
       "      <td>0.829862</td>\n",
       "      <td>0.653548</td>\n",
       "      <td>0.393952</td>\n",
       "      <td>DeepLocT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.941977</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>0.872774</td>\n",
       "      <td>0.874564</td>\n",
       "      <td>0.873669</td>\n",
       "      <td>0.741610</td>\n",
       "      <td>0.302673</td>\n",
       "      <td>DeepLocT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.940310</td>\n",
       "      <td>0.872802</td>\n",
       "      <td>0.837150</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>0.867181</td>\n",
       "      <td>0.735881</td>\n",
       "      <td>0.281512</td>\n",
       "      <td>DeepLocT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.908206</td>\n",
       "      <td>0.825233</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.829920</td>\n",
       "      <td>0.649932</td>\n",
       "      <td>0.366192</td>\n",
       "      <td>DeepLocT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.868059</td>\n",
       "      <td>0.830403</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.818815</td>\n",
       "      <td>0.833072</td>\n",
       "      <td>0.657418</td>\n",
       "      <td>0.374341</td>\n",
       "      <td>DeepLocT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.937934</td>\n",
       "      <td>0.876939</td>\n",
       "      <td>0.798982</td>\n",
       "      <td>0.930314</td>\n",
       "      <td>0.864648</td>\n",
       "      <td>0.743574</td>\n",
       "      <td>0.450767</td>\n",
       "      <td>DeepLocT5FT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auc       acc       sen       spe       bac  \\\n",
       "LGBMClassifier          0.916598  0.864529  0.821883  0.893728  0.857806   \n",
       "RandomForestClassifier  0.885594  0.825233  0.659033  0.939024  0.799029   \n",
       "SVMClassifier           0.839267  0.815926  0.786260  0.836237  0.811248   \n",
       "NNClassifier            0.915800  0.849018  0.821883  0.867596  0.844739   \n",
       "LGBMClassifier          0.920991  0.844881  0.809160  0.869338  0.839249   \n",
       "RandomForestClassifier  0.859625  0.804550  0.648855  0.911150  0.780002   \n",
       "SVMClassifier           0.494856  0.593588  0.000000  1.000000  0.500000   \n",
       "NNClassifier            0.925739  0.864529  0.832061  0.886760  0.859410   \n",
       "LGBMClassifier          0.936201  0.855222  0.862595  0.850174  0.856385   \n",
       "RandomForestClassifier  0.903219  0.807653  0.839695  0.785714  0.812704   \n",
       "SVMClassifier           0.864701  0.830403  0.826972  0.832753  0.829862   \n",
       "NNClassifier            0.941977  0.873837  0.872774  0.874564  0.873669   \n",
       "LGBMClassifier          0.940310  0.872802  0.837150  0.897213  0.867181   \n",
       "RandomForestClassifier  0.908206  0.825233  0.854962  0.804878  0.829920   \n",
       "SVMClassifier           0.868059  0.830403  0.847328  0.818815  0.833072   \n",
       "NNClassifier            0.937934  0.876939  0.798982  0.930314  0.864648   \n",
       "\n",
       "                             mcc    cutoff           data  \n",
       "LGBMClassifier          0.718339  0.317998    DeepLocBERT  \n",
       "RandomForestClassifier  0.638578  0.472167    DeepLocBERT  \n",
       "SVMClassifier           0.620150  0.393979    DeepLocBERT  \n",
       "NNClassifier            0.687880  0.351950    DeepLocBERT  \n",
       "LGBMClassifier          0.678498  0.291704  DeepLocAlbert  \n",
       "RandomForestClassifier  0.591402  0.462963  DeepLocAlbert  \n",
       "SVMClassifier           0.000000  1.406519  DeepLocAlbert  \n",
       "NNClassifier            0.719111  0.318228  DeepLocAlbert  \n",
       "LGBMClassifier          0.705354  0.276454      DeepLocT5  \n",
       "RandomForestClassifier  0.615582  0.349314      DeepLocT5  \n",
       "SVMClassifier           0.653548  0.393952      DeepLocT5  \n",
       "NNClassifier            0.741610  0.302673      DeepLocT5  \n",
       "LGBMClassifier          0.735881  0.281512    DeepLocT5FT  \n",
       "RandomForestClassifier  0.649932  0.366192    DeepLocT5FT  \n",
       "SVMClassifier           0.657418  0.374341    DeepLocT5FT  \n",
       "NNClassifier            0.743574  0.450767    DeepLocT5FT  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.concat(df_results)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('../results/summary/LMDeepLoc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3e12de8d4f511a3f40a134d20c84f219b709a35adcae8dcc2b376a736afcf2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bioenv_ver0.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
