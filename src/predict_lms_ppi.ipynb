{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import model_from_json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_cutoff(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def evaluate_clf(y_true, y_pred, cutoff):\n",
    "    pred_label = (y_pred >= cutoff) * 1\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred_label).ravel()\n",
    "    accuracy = accuracy_score(y_true, pred_label)\n",
    "    balanced_accuracy = (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "    mcc = matthews_corrcoef(y_true, pred_label)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'auc': [auc],\n",
    "        'acc': [accuracy],\n",
    "        'sen': [sensitivity],\n",
    "        'spe': [specificity],\n",
    "        'bac': [balanced_accuracy],\n",
    "        'mcc': [mcc],\n",
    "        'cutoff': [cutoff]\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def load_lgb(path):\n",
    "    if 'LGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_rf(path):\n",
    "    if 'RandomForest' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_svm(path):\n",
    "    if 'SVM' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb(path):\n",
    "    if 'XGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_nn(path_json, path_h5, path_transformer):\n",
    "    if 'NN' in path_json:\n",
    "        with open(path_json, 'r') as f:\n",
    "            json_string = f.read()\n",
    "        model = model_from_json(json_string)\n",
    "        model.load_weights(path_h5)\n",
    "        if os.path.exists(path_transformer):\n",
    "            with open(path_transformer, 'rb') as f:\n",
    "                transformer = pickle.load(f)\n",
    "        else:\n",
    "            transformer = None\n",
    "        return model, transformer\n",
    "\n",
    "\n",
    "def sort_preds(PREDS, IDXES):\n",
    "    va_idxes = np.concatenate(IDXES)\n",
    "    order = np.argsort(va_idxes)\n",
    "    va_preds = np.concatenate(PREDS)\n",
    "    return va_preds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurosaki/Document/Research/PJ0/Repository/Bioenv/src\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "print(root)\n",
    "\n",
    "n_splits_ncv = 5\n",
    "seed_ncv = 1712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPPIBERT\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "       auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.98179  0.939185  0.933662  0.941146  0.937404  0.849462  0.218815\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.93608  0.892263  0.856605  0.904928  0.880767  0.734608  0.227997\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:36:29.244243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-20 11:36:37.700159: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-20 11:36:37.700558: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2198655000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac      mcc    cutoff\n",
      "0  0.963963  0.909954  0.911066  0.909559  0.910312  0.78347  0.249355\n",
      "****************************************************************************************************\n",
      "DeepPPIAlbert\n",
      "X_shape (65851, 8192)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc      sen       spe       bac       mcc   cutoff\n",
      "0  0.981714  0.937894  0.93482  0.938985  0.936903  0.846838  0.21878\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc   cutoff\n",
      "0  0.890483  0.844203  0.799537  0.860068  0.829802  0.625652  0.26431\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.974524  0.926809  0.931344  0.925198  0.928271  0.822544  0.226008\n",
      "****************************************************************************************************\n",
      "DeepPPIT5\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.982639  0.942677  0.937428  0.944542  0.940985  0.857768  0.219068\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen      spe       bac       mcc    cutoff\n",
      "0  0.932926  0.887556  0.848494  0.90143  0.874962  0.723084  0.206306\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.971292  0.919824  0.922364  0.918922  0.920643  0.806148  0.240622\n",
      "****************************************************************************************************\n",
      "DeepPPIT5FT\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "       auc       acc       sen       spe       bac      mcc    cutoff\n",
      "0  0.98301  0.939944  0.938586  0.940426  0.939506  0.85195  0.209585\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.942272  0.892567  0.869351  0.900813  0.885082  0.738367  0.203009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen      spe       bac       mcc   cutoff\n",
      "0  0.970164  0.913978  0.923233  0.91069  0.916962  0.794465  0.24365\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "f_names = [\n",
    "        'DeepPPIEmbedd_BERT_BFD.csv',\n",
    "        'DeepPPIEmbedd_Albert_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_FT.csv'\n",
    "    ]\n",
    "data_names = [\n",
    "    'DeepPPIBERT',\n",
    "        'DeepPPIAlbert',\n",
    "        'DeepPPIT5',\n",
    "        'DeepPPIT5FT'\n",
    "    ]\n",
    "\n",
    "results = {\n",
    "    data:{\n",
    "        i:{\n",
    "        'LGBMClassifier':None,\n",
    "        'RandomForestClassifier':None,\n",
    "        'NNClassifier':None\n",
    "        }\n",
    "        for i in range(5)\n",
    "        }\n",
    "        for data in data_names\n",
    "}\n",
    "\n",
    "for f_name, data_name in zip(f_names, data_names):\n",
    "     # load core data set for PPI classification\n",
    "    df = pd.read_csv('../data/DeepPPI/DeepPPIAll.csv')\n",
    "    protein_a = np.array(df['proteinA'])\n",
    "    protein_b = np.array(df['proteinB'])\n",
    "    y = np.array(df['interaction'])\n",
    "\n",
    "    # load features\n",
    "    df_feature = pd.read_csv(f'../data/DeepPPI/{f_name}')\n",
    "    # pre-processing of protein features\n",
    "    feature_dict = {\n",
    "        Id: np.array(df_feature[df_feature.iloc[:,0]==Id].iloc[:,1:])\n",
    "        for Id in df_feature.iloc[:,0].tolist()\n",
    "    }\n",
    "    feature_a, feature_b = [], []\n",
    "    for a, b in zip(protein_a, protein_b):\n",
    "        feature_a.append(feature_dict[a])\n",
    "        feature_b.append(feature_dict[b])\n",
    "    X_a, X_b = np.concatenate(feature_a), np.concatenate(feature_b)\n",
    "    X = np.concatenate([X_a, X_b], axis=1)\n",
    "    print(data_name)\n",
    "    print('X_shape', X.shape)\n",
    "    print('y_shape', y.shape)\n",
    "    skf_outer = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True) \n",
    "    outer_idxes = list(skf_outer.split(X, y))\n",
    "\n",
    "    # evaluate ptrained model\n",
    "    for i, (inner_idx, te_idx) in enumerate(outer_idxes):\n",
    "        if i == 0:\n",
    "            print('*'*100)\n",
    "            print('fold', i)\n",
    "            for model_name in ['LGBMClassifier', 'RandomForestClassifier', 'NNClassifier']:\n",
    "                skf_inner = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True)\n",
    "                inner_idxes = list(skf_outer.split(X[inner_idx], y[inner_idx]))\n",
    "                print('-'*100)\n",
    "                print(model_name)\n",
    "                te_preds, cutoffs = [], []\n",
    "                for j, (tr_idx, va_idx) in enumerate(inner_idxes):\n",
    "                    if 'LGB' in model_name:\n",
    "                        model = load_lgb(f'../results/models/{data_name}/LGBMClassifier/LGBMClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                    elif 'RandomForest' in model_name:\n",
    "                        model = load_rf(f'../results/models/{data_name}/RandomForestClassifier/RandomForestClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx])[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx])[:,1]\n",
    "                    elif 'NN' in model_name:\n",
    "                        model, transformer = load_nn(\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_i{i}_architecture.json',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_trainedweight.h5',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_transformer.pkl'\n",
    "                            )\n",
    "                        va_pred = model.predict(transformer.transform(X[inner_idx][va_idx]))\n",
    "                        te_pred = model.predict(transformer.transform(X[te_idx]))\n",
    "                    cutoff = roc_cutoff(y[inner_idx][va_idx], va_pred)\n",
    "                    te_preds.append(te_pred)\n",
    "                    cutoffs.append(cutoff)\n",
    "                te_pred_mean = np.mean(te_preds, axis=0)\n",
    "                metrics = evaluate_clf(y[te_idx], te_pred_mean, np.mean(cutoffs))\n",
    "                print(pd.DataFrame(metrics))\n",
    "                results[data_name][i][model_name] = pd.DataFrame(metrics)\n",
    "            print('*'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "for data_name in data_names:\n",
    "    result_dict = results[data_name][0]\n",
    "    df_result = pd.concat([v for v in result_dict.values()])\n",
    "    df_result['data'] = data_name\n",
    "    df_result.index = list(result_dict.keys())[-len(df_result):]\n",
    "    df_results.append(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>sen</th>\n",
       "      <th>spe</th>\n",
       "      <th>bac</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.981790</td>\n",
       "      <td>0.939185</td>\n",
       "      <td>0.933662</td>\n",
       "      <td>0.941146</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.218815</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.936080</td>\n",
       "      <td>0.892263</td>\n",
       "      <td>0.856605</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.880767</td>\n",
       "      <td>0.734608</td>\n",
       "      <td>0.227997</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.963963</td>\n",
       "      <td>0.909954</td>\n",
       "      <td>0.911066</td>\n",
       "      <td>0.909559</td>\n",
       "      <td>0.910312</td>\n",
       "      <td>0.783470</td>\n",
       "      <td>0.249355</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.981714</td>\n",
       "      <td>0.937894</td>\n",
       "      <td>0.934820</td>\n",
       "      <td>0.938985</td>\n",
       "      <td>0.936903</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.218780</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.890483</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.799537</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.829802</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>0.264310</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.974524</td>\n",
       "      <td>0.926809</td>\n",
       "      <td>0.931344</td>\n",
       "      <td>0.925198</td>\n",
       "      <td>0.928271</td>\n",
       "      <td>0.822544</td>\n",
       "      <td>0.226008</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.982639</td>\n",
       "      <td>0.942677</td>\n",
       "      <td>0.937428</td>\n",
       "      <td>0.944542</td>\n",
       "      <td>0.940985</td>\n",
       "      <td>0.857768</td>\n",
       "      <td>0.219068</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.932926</td>\n",
       "      <td>0.887556</td>\n",
       "      <td>0.848494</td>\n",
       "      <td>0.901430</td>\n",
       "      <td>0.874962</td>\n",
       "      <td>0.723084</td>\n",
       "      <td>0.206306</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.971292</td>\n",
       "      <td>0.919824</td>\n",
       "      <td>0.922364</td>\n",
       "      <td>0.918922</td>\n",
       "      <td>0.920643</td>\n",
       "      <td>0.806148</td>\n",
       "      <td>0.240622</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.983010</td>\n",
       "      <td>0.939944</td>\n",
       "      <td>0.938586</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.939506</td>\n",
       "      <td>0.851950</td>\n",
       "      <td>0.209585</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.942272</td>\n",
       "      <td>0.892567</td>\n",
       "      <td>0.869351</td>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.885082</td>\n",
       "      <td>0.738367</td>\n",
       "      <td>0.203009</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.970164</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.923233</td>\n",
       "      <td>0.910690</td>\n",
       "      <td>0.916962</td>\n",
       "      <td>0.794465</td>\n",
       "      <td>0.243650</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auc       acc       sen       spe       bac  \\\n",
       "LGBMClassifier          0.981790  0.939185  0.933662  0.941146  0.937404   \n",
       "RandomForestClassifier  0.936080  0.892263  0.856605  0.904928  0.880767   \n",
       "NNClassifier            0.963963  0.909954  0.911066  0.909559  0.910312   \n",
       "LGBMClassifier          0.981714  0.937894  0.934820  0.938985  0.936903   \n",
       "RandomForestClassifier  0.890483  0.844203  0.799537  0.860068  0.829802   \n",
       "NNClassifier            0.974524  0.926809  0.931344  0.925198  0.928271   \n",
       "LGBMClassifier          0.982639  0.942677  0.937428  0.944542  0.940985   \n",
       "RandomForestClassifier  0.932926  0.887556  0.848494  0.901430  0.874962   \n",
       "NNClassifier            0.971292  0.919824  0.922364  0.918922  0.920643   \n",
       "LGBMClassifier          0.983010  0.939944  0.938586  0.940426  0.939506   \n",
       "RandomForestClassifier  0.942272  0.892567  0.869351  0.900813  0.885082   \n",
       "NNClassifier            0.970164  0.913978  0.923233  0.910690  0.916962   \n",
       "\n",
       "                             mcc    cutoff           data  \n",
       "LGBMClassifier          0.849462  0.218815    DeepPPIBERT  \n",
       "RandomForestClassifier  0.734608  0.227997    DeepPPIBERT  \n",
       "NNClassifier            0.783470  0.249355    DeepPPIBERT  \n",
       "LGBMClassifier          0.846838  0.218780  DeepPPIAlbert  \n",
       "RandomForestClassifier  0.625652  0.264310  DeepPPIAlbert  \n",
       "NNClassifier            0.822544  0.226008  DeepPPIAlbert  \n",
       "LGBMClassifier          0.857768  0.219068      DeepPPIT5  \n",
       "RandomForestClassifier  0.723084  0.206306      DeepPPIT5  \n",
       "NNClassifier            0.806148  0.240622      DeepPPIT5  \n",
       "LGBMClassifier          0.851950  0.209585    DeepPPIT5FT  \n",
       "RandomForestClassifier  0.738367  0.203009    DeepPPIT5FT  \n",
       "NNClassifier            0.794465  0.243650    DeepPPIT5FT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.concat(df_results)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('../results/summary/LMDeepPPI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3e12de8d4f511a3f40a134d20c84f219b709a35adcae8dcc2b376a736afcf2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bioenv_ver0.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
