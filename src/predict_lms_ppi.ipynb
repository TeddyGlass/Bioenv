{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import model_from_json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_cutoff(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def evaluate_clf(y_true, y_pred, cutoff):\n",
    "    pred_label = (y_pred >= cutoff) * 1\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred_label).ravel()\n",
    "    accuracy = accuracy_score(y_true, pred_label)\n",
    "    balanced_accuracy = (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "    mcc = matthews_corrcoef(y_true, pred_label)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'auc': [auc],\n",
    "        'acc': [accuracy],\n",
    "        'sen': [sensitivity],\n",
    "        'spe': [specificity],\n",
    "        'bac': [balanced_accuracy],\n",
    "        'mcc': [mcc],\n",
    "        'cutoff': [cutoff]\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def load_lgb(path):\n",
    "    if 'LGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_rf(path):\n",
    "    if 'RandomForest' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_svm(path):\n",
    "    if 'SVM' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb(path):\n",
    "    if 'XGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_nn(path_json, path_h5, path_transformer):\n",
    "    if 'NN' in path_json:\n",
    "        with open(path_json, 'r') as f:\n",
    "            json_string = f.read()\n",
    "        model = model_from_json(json_string)\n",
    "        model.load_weights(path_h5)\n",
    "        if os.path.exists(path_transformer):\n",
    "            with open(path_transformer, 'rb') as f:\n",
    "                transformer = pickle.load(f)\n",
    "        else:\n",
    "            transformer = None\n",
    "        return model, transformer\n",
    "\n",
    "\n",
    "def sort_preds(PREDS, IDXES):\n",
    "    va_idxes = np.concatenate(IDXES)\n",
    "    order = np.argsort(va_idxes)\n",
    "    va_preds = np.concatenate(PREDS)\n",
    "    return va_preds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurosaki/Document/Research/PJ0/Repository/Bioenv/src\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "print(root)\n",
    "\n",
    "n_splits_ncv = 5\n",
    "seed_ncv = 1712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPPIBERT\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "       auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.98096  0.942753  0.926419  0.948554  0.937487  0.856277  0.244995\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.934172  0.896211  0.843279  0.915012  0.879146  0.739729  0.260835\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 11:37:12.727493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 11:37:21.027225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-15 11:37:21.027604: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2198655000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.948846  0.894769  0.875435  0.901636  0.888535  0.744296  0.229315\n",
      "****************************************************************************************************\n",
      "DeepPPIAlbert\n",
      "X_shape (65851, 8192)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.980465  0.939564  0.929896  0.942998  0.936447  0.849684  0.236839\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc      acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.890095  0.85339  0.784183  0.877971  0.831077  0.638169  0.272296\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc      sen       spe       bac       mcc    cutoff\n",
      "0  0.968254  0.921494  0.90759  0.926433  0.917011  0.806545  0.227431\n",
      "****************************************************************************************************\n",
      "DeepPPIT5\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.981526  0.944575  0.931344  0.949275  0.940309  0.861093  0.242883\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc      sen       spe       bac       mcc    cutoff\n",
      "0  0.930297  0.879052  0.86095  0.885482  0.873216  0.709666  0.186697\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.964751  0.914585  0.900348  0.919642  0.909995  0.790523  0.240993\n",
      "****************************************************************************************************\n",
      "DeepPPIT5FT\n",
      "X_shape (65851, 2048)\n",
      "y_shape (65851,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc       sen      spe       bac       mcc    cutoff\n",
      "0  0.981817  0.940475  0.934241  0.94269  0.938465  0.852395  0.218906\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       auc       acc       sen      spe       bac       mcc    cutoff\n",
      "0  0.93963  0.897806  0.852549  0.91388  0.883215  0.745103  0.237156\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen       spe     bac      mcc    cutoff\n",
      "0  0.957855  0.897426  0.894554  0.898446  0.8965  0.75445  0.211178\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "f_names = [\n",
    "        'DeepPPIEmbedd_BERT_BFD.csv',\n",
    "        'DeepPPIEmbedd_Albert_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_BFD.csv',\n",
    "        'DeepPPIEmbedd_T5_FT.csv'\n",
    "    ]\n",
    "data_names = [\n",
    "    'DeepPPIBERT',\n",
    "        'DeepPPIAlbert',\n",
    "        'DeepPPIT5',\n",
    "        'DeepPPIT5FT'\n",
    "    ]\n",
    "\n",
    "results = {\n",
    "    data:{\n",
    "        i:{\n",
    "        'LGBMClassifier':None,\n",
    "        'RandomForestClassifier':None,\n",
    "        'NNClassifier':None\n",
    "        }\n",
    "        for i in range(5)\n",
    "        }\n",
    "        for data in data_names\n",
    "}\n",
    "\n",
    "for f_name, data_name in zip(f_names, data_names):\n",
    "     # load core data set for PPI classification\n",
    "    df = pd.read_csv('../data/DeepPPI/DeepPPIAll.csv')\n",
    "    protein_a = np.array(df['proteinA'])\n",
    "    protein_b = np.array(df['proteinB'])\n",
    "    y = np.array(df['interaction'])\n",
    "\n",
    "    # load features\n",
    "    df_feature = pd.read_csv(f'../data/DeepPPI/{f_name}')\n",
    "    # pre-processing of protein features\n",
    "    feature_dict = {\n",
    "        Id: np.array(df_feature[df_feature.iloc[:,0]==Id].iloc[:,1:])\n",
    "        for Id in df_feature.iloc[:,0].tolist()\n",
    "    }\n",
    "    feature_a, feature_b = [], []\n",
    "    for a, b in zip(protein_a, protein_b):\n",
    "        feature_a.append(feature_dict[a])\n",
    "        feature_b.append(feature_dict[b])\n",
    "    X_a, X_b = np.concatenate(feature_a), np.concatenate(feature_b)\n",
    "    X = np.concatenate([X_a, X_b], axis=1)\n",
    "    print(data_name)\n",
    "    print('X_shape', X.shape)\n",
    "    print('y_shape', y.shape)\n",
    "    skf_outer = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True) \n",
    "    outer_idxes = list(skf_outer.split(X, y))\n",
    "\n",
    "    # evaluate ptrained model\n",
    "    for i, (inner_idx, te_idx) in enumerate(outer_idxes):\n",
    "        if i == 0:\n",
    "            print('*'*100)\n",
    "            print('fold', i)\n",
    "            for model_name in ['LGBMClassifier', 'RandomForestClassifier', 'NNClassifier']:\n",
    "                skf_inner = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True)\n",
    "                inner_idxes = list(skf_outer.split(X[inner_idx], y[inner_idx]))\n",
    "                print('-'*100)\n",
    "                print(model_name)\n",
    "                te_preds, cutoffs = [], []\n",
    "                for j, (tr_idx, va_idx) in enumerate(inner_idxes):\n",
    "                    if 'LGB' in model_name:\n",
    "                        model = load_lgb(f'../results/models/{data_name}/LGBMClassifier/LGBMClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx], num_iterations=model.best_iteration_)[:,1]\n",
    "                    elif 'RandomForest' in model_name:\n",
    "                        model = load_rf(f'../results/models/{data_name}/RandomForestClassifier/RandomForestClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        va_pred = model.predict_proba(X[inner_idx][va_idx])[:,1]\n",
    "                        te_pred = model.predict_proba(X[te_idx])[:,1]\n",
    "                    elif 'NN' in model_name:\n",
    "                        model, transformer = load_nn(\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_i{i}_architecture.json',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_trainedweight.h5',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_transformer.pkl'\n",
    "                            )\n",
    "                        va_pred = model.predict(transformer.transform(X[inner_idx][va_idx]))\n",
    "                        te_pred = model.predict(transformer.transform(X[te_idx]))\n",
    "                cutoff = roc_cutoff(y[inner_idx][va_idx], va_pred)\n",
    "                te_preds.append(te_pred)\n",
    "                cutoffs.append(cutoff)\n",
    "                te_pred_mean = np.mean(te_preds, axis=0)\n",
    "                metrics = evaluate_clf(y[te_idx], te_pred_mean, np.mean(cutoffs))\n",
    "                print(pd.DataFrame(metrics))\n",
    "                results[data_name][i][model_name] = pd.DataFrame(metrics)\n",
    "            print('*'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "for data_name in data_names:\n",
    "    result_dict = results[data_name][0]\n",
    "    df_result = pd.concat([v for v in result_dict.values()])\n",
    "    df_result['data'] = data_name\n",
    "    df_result.index = list(result_dict.keys())[-len(df_result):]\n",
    "    df_results.append(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>sen</th>\n",
       "      <th>spe</th>\n",
       "      <th>bac</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.980960</td>\n",
       "      <td>0.942753</td>\n",
       "      <td>0.926419</td>\n",
       "      <td>0.948554</td>\n",
       "      <td>0.937487</td>\n",
       "      <td>0.856277</td>\n",
       "      <td>0.244995</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.934172</td>\n",
       "      <td>0.896211</td>\n",
       "      <td>0.843279</td>\n",
       "      <td>0.915012</td>\n",
       "      <td>0.879146</td>\n",
       "      <td>0.739729</td>\n",
       "      <td>0.260835</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.948846</td>\n",
       "      <td>0.894769</td>\n",
       "      <td>0.875435</td>\n",
       "      <td>0.901636</td>\n",
       "      <td>0.888535</td>\n",
       "      <td>0.744296</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>DeepPPIBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.980465</td>\n",
       "      <td>0.939564</td>\n",
       "      <td>0.929896</td>\n",
       "      <td>0.942998</td>\n",
       "      <td>0.936447</td>\n",
       "      <td>0.849684</td>\n",
       "      <td>0.236839</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.890095</td>\n",
       "      <td>0.853390</td>\n",
       "      <td>0.784183</td>\n",
       "      <td>0.877971</td>\n",
       "      <td>0.831077</td>\n",
       "      <td>0.638169</td>\n",
       "      <td>0.272296</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.921494</td>\n",
       "      <td>0.907590</td>\n",
       "      <td>0.926433</td>\n",
       "      <td>0.917011</td>\n",
       "      <td>0.806545</td>\n",
       "      <td>0.227431</td>\n",
       "      <td>DeepPPIAlbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.944575</td>\n",
       "      <td>0.931344</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>0.861093</td>\n",
       "      <td>0.242883</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.930297</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.860950</td>\n",
       "      <td>0.885482</td>\n",
       "      <td>0.873216</td>\n",
       "      <td>0.709666</td>\n",
       "      <td>0.186697</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.964751</td>\n",
       "      <td>0.914585</td>\n",
       "      <td>0.900348</td>\n",
       "      <td>0.919642</td>\n",
       "      <td>0.909995</td>\n",
       "      <td>0.790523</td>\n",
       "      <td>0.240993</td>\n",
       "      <td>DeepPPIT5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.940475</td>\n",
       "      <td>0.934241</td>\n",
       "      <td>0.942690</td>\n",
       "      <td>0.938465</td>\n",
       "      <td>0.852395</td>\n",
       "      <td>0.218906</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.939630</td>\n",
       "      <td>0.897806</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>0.913880</td>\n",
       "      <td>0.883215</td>\n",
       "      <td>0.745103</td>\n",
       "      <td>0.237156</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.957855</td>\n",
       "      <td>0.897426</td>\n",
       "      <td>0.894554</td>\n",
       "      <td>0.898446</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>0.754450</td>\n",
       "      <td>0.211178</td>\n",
       "      <td>DeepPPIT5FT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auc       acc       sen       spe       bac  \\\n",
       "LGBMClassifier          0.980960  0.942753  0.926419  0.948554  0.937487   \n",
       "RandomForestClassifier  0.934172  0.896211  0.843279  0.915012  0.879146   \n",
       "NNClassifier            0.948846  0.894769  0.875435  0.901636  0.888535   \n",
       "LGBMClassifier          0.980465  0.939564  0.929896  0.942998  0.936447   \n",
       "RandomForestClassifier  0.890095  0.853390  0.784183  0.877971  0.831077   \n",
       "NNClassifier            0.968254  0.921494  0.907590  0.926433  0.917011   \n",
       "LGBMClassifier          0.981526  0.944575  0.931344  0.949275  0.940309   \n",
       "RandomForestClassifier  0.930297  0.879052  0.860950  0.885482  0.873216   \n",
       "NNClassifier            0.964751  0.914585  0.900348  0.919642  0.909995   \n",
       "LGBMClassifier          0.981817  0.940475  0.934241  0.942690  0.938465   \n",
       "RandomForestClassifier  0.939630  0.897806  0.852549  0.913880  0.883215   \n",
       "NNClassifier            0.957855  0.897426  0.894554  0.898446  0.896500   \n",
       "\n",
       "                             mcc    cutoff           data  \n",
       "LGBMClassifier          0.856277  0.244995    DeepPPIBERT  \n",
       "RandomForestClassifier  0.739729  0.260835    DeepPPIBERT  \n",
       "NNClassifier            0.744296  0.229315    DeepPPIBERT  \n",
       "LGBMClassifier          0.849684  0.236839  DeepPPIAlbert  \n",
       "RandomForestClassifier  0.638169  0.272296  DeepPPIAlbert  \n",
       "NNClassifier            0.806545  0.227431  DeepPPIAlbert  \n",
       "LGBMClassifier          0.861093  0.242883      DeepPPIT5  \n",
       "RandomForestClassifier  0.709666  0.186697      DeepPPIT5  \n",
       "NNClassifier            0.790523  0.240993      DeepPPIT5  \n",
       "LGBMClassifier          0.852395  0.218906    DeepPPIT5FT  \n",
       "RandomForestClassifier  0.745103  0.237156    DeepPPIT5FT  \n",
       "NNClassifier            0.754450  0.211178    DeepPPIT5FT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.concat(df_results)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('../results/summary/LMDeepPPI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3e12de8d4f511a3f40a134d20c84f219b709a35adcae8dcc2b376a736afcf2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bioenv_ver0.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
