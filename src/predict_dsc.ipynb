{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "\n",
    "from machine_learing.core.utils import fill_na_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_cutoff(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def evaluate_clf(y_true, y_pred, cutoff):\n",
    "    pred_label = (y_pred >= cutoff) * 1\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred_label).ravel()\n",
    "    accuracy = accuracy_score(y_true, pred_label)\n",
    "    balanced_accuracy = (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "    mcc = matthews_corrcoef(y_true, pred_label)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'auc': [auc],\n",
    "        'acc': [accuracy],\n",
    "        'sen': [sensitivity],\n",
    "        'spe': [specificity],\n",
    "        'bac': [balanced_accuracy],\n",
    "        'mcc': [mcc],\n",
    "        'cutoff': [cutoff]\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def load_lgb(path):\n",
    "    if 'LGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_rf(path):\n",
    "    if 'RandomForest' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_svm(path):\n",
    "    if 'SVM' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb(path):\n",
    "    if 'XGB' in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_nn(path_json, path_h5, path_transformer):\n",
    "    if 'NN' in path_json:\n",
    "        with open(path_json, 'r') as f:\n",
    "            json_string = f.read()\n",
    "        model = model_from_json(json_string)\n",
    "        model.load_weights(path_h5)\n",
    "        if os.path.exists(path_transformer):\n",
    "            with open(path_transformer, 'rb') as f:\n",
    "                transformer = pickle.load(f)\n",
    "        else:\n",
    "            transformer = None\n",
    "        return model, transformer\n",
    "\n",
    "\n",
    "def sort_preds(PREDS, IDXES):\n",
    "    va_idxes = np.concatenate(IDXES)\n",
    "    order = np.argsort(va_idxes)\n",
    "    va_preds = np.concatenate(PREDS)\n",
    "    return va_preds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kurosaki/Document/Research/PJ0/Repository/Bioenv/src\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "print(root)\n",
    "\n",
    "n_splits_ncv = 5\n",
    "seed_ncv = 1712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLocAAindex\n",
      "X_shape (4832, 566)\n",
      "y_shape (4832,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "       auc       acc       sen       spe      bac       mcc    cutoff\n",
      "0  0.81733  0.754912  0.605598  0.857143  0.73137  0.483018  0.429081\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.785683  0.749741  0.600509  0.851916  0.726213  0.471879  0.419848\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SVMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.752795  0.722854  0.559796  0.834495  0.697146  0.413228  0.413129\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 11:33:22.116223: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-20 11:33:23.417567: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-20 11:33:23.420008: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2198655000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.818093  0.761117  0.585242  0.881533  0.733387  0.496522  0.480465\n",
      "****************************************************************************************************\n",
      "DeepLocAutocorr\n",
      "X_shape (4832, 720)\n",
      "y_shape (4832,)\n",
      "****************************************************************************************************\n",
      "fold 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.802143  0.752844  0.679389  0.803136  0.741263  0.485245  0.410101\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend ThreadingBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.721729  0.690796  0.526718  0.803136  0.664927  0.344307  0.433009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SVMClassifier\n",
      "        auc       acc  sen  spe  bac  mcc    cutoff\n",
      "0  0.427408  0.593588  0.0  1.0  0.5  0.0  0.674078\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NNClassifier\n",
      "        auc       acc       sen       spe       bac       mcc    cutoff\n",
      "0  0.767444  0.726991  0.582697  0.825784  0.704241  0.423463  0.471754\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "f_names = [\n",
    "        'DeepLocDescriptorAAindex.csv',\n",
    "        'DeepLocDescriptorAutocorrelation.csv'\n",
    "    ]\n",
    "data_names = [\n",
    "    'DeepLocAAindex',\n",
    "    'DeepLocAutocorr'\n",
    "    ]\n",
    "\n",
    "results = {\n",
    "    data:{\n",
    "        i:{\n",
    "        'LGBMClassifier':None,\n",
    "        'RandomForestClassifier':None,\n",
    "        'SVMClassifier':None,\n",
    "        'NNClassifier':None\n",
    "        }\n",
    "        for i in range(5)\n",
    "        }\n",
    "        for data in data_names\n",
    "}\n",
    "\n",
    "for f_name, data_name in zip(f_names, data_names):\n",
    "    df = pd.read_csv(f'../data/DeepLoc/{f_name}')\n",
    "    M_idx = df.iloc[:,2]=='M'\n",
    "    S_idx = df.iloc[:,2]=='S'\n",
    "    df = pd.concat([df[M_idx], df[S_idx]], axis=0)\n",
    "    X = np.array(df.iloc[:,3:])\n",
    "    y = np.concatenate([np.array([1]*sum(M_idx)), np.array([0]*sum(S_idx))]).flatten()\n",
    "    print(data_name)\n",
    "    print('X_shape', X.shape)\n",
    "    print('y_shape', y.shape)\n",
    "    skf_outer = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True) \n",
    "    outer_idxes = list(skf_outer.split(X, y))\n",
    "\n",
    "    # evaluate ptrained model\n",
    "    for i, (inner_idx, te_idx) in enumerate(outer_idxes):\n",
    "        if i == 0:\n",
    "            print('*'*100)\n",
    "            print('fold', i)\n",
    "            for model_name in ['LGBMClassifier', 'RandomForestClassifier', 'SVMClassifier', 'NNClassifier']:\n",
    "                skf_inner = StratifiedKFold(n_splits=n_splits_ncv, random_state=seed_ncv, shuffle=True)\n",
    "                inner_idxes = list(skf_outer.split(X[inner_idx], y[inner_idx]))\n",
    "                print('-'*100)\n",
    "                print(model_name)\n",
    "                te_preds, cutoffs = [], []\n",
    "                for j, (tr_idx, va_idx) in enumerate(inner_idxes):\n",
    "                    if 'LGB' in model_name:\n",
    "                        model = load_lgb(f'../results/models/{data_name}/LGBMClassifier/LGBMClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        X_valid = X[inner_idx][va_idx]\n",
    "                        X_test = X[te_idx]\n",
    "                        va_pred = model.predict_proba(X_valid, num_iterations=model.best_iteration_)[:,1]\n",
    "                        te_pred = model.predict_proba(X_test, num_iterations=model.best_iteration_)[:,1]\n",
    "                    elif 'RandomForest' in model_name:\n",
    "                        model = load_rf(f'../results/models/{data_name}/RandomForestClassifier/RandomForestClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        X_valid = fill_na_mean(X[inner_idx][va_idx])\n",
    "                        X_test = fill_na_mean(X[te_idx])\n",
    "                        va_pred = model.predict_proba(X_valid)[:,1]\n",
    "                        te_pred = model.predict_proba(X_test)[:,1]\n",
    "                    elif 'SVM' in model_name:\n",
    "                        model = load_svm(f'../results/models/{data_name}/SVMClassifier/SVMClassifier_ij{i}{j}_trainedmodel.pkl')\n",
    "                        X_valid = fill_na_mean(X[inner_idx][va_idx])\n",
    "                        X_test = fill_na_mean(X[te_idx])\n",
    "                        va_pred = model.predict_proba(X_valid)[:,1]\n",
    "                        te_pred = model.predict_proba(X_test)[:,1]\n",
    "                    elif 'NN' in model_name:\n",
    "                        model, transformer = load_nn(\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_i{i}_architecture.json',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_trainedweight.h5',\n",
    "                            f'../results/models/{data_name}/NNClassifier/NNClassifier_ij{i}{j}_transformer.pkl'\n",
    "                            )\n",
    "                        X_valid = fill_na_mean(X[inner_idx][va_idx])\n",
    "                        X_test = fill_na_mean(X[te_idx])\n",
    "                        va_pred = model.predict(transformer.transform(X_valid))\n",
    "                        te_pred = model.predict(transformer.transform(X_test))\n",
    "                    cutoff = roc_cutoff(y[inner_idx][va_idx], va_pred)\n",
    "                    te_preds.append(te_pred)\n",
    "                    cutoffs.append(cutoff)\n",
    "                te_pred_mean = np.mean(te_preds, axis=0)\n",
    "                metrics = evaluate_clf(y[te_idx], te_pred_mean, np.mean(cutoffs))\n",
    "                print(pd.DataFrame(metrics))\n",
    "                results[data_name][i][model_name] = pd.DataFrame(metrics)\n",
    "            print('*'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "for data_name in data_names:\n",
    "    result_dict = results[data_name][0]\n",
    "    df_result = pd.concat([v for v in result_dict.values()])\n",
    "    df_result['data'] = data_name\n",
    "    df_result.index = list(result_dict.keys())[-len(df_result):]\n",
    "    df_results.append(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>sen</th>\n",
       "      <th>spe</th>\n",
       "      <th>bac</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.817330</td>\n",
       "      <td>0.754912</td>\n",
       "      <td>0.605598</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.731370</td>\n",
       "      <td>0.483018</td>\n",
       "      <td>0.429081</td>\n",
       "      <td>DeepLocAAindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.785683</td>\n",
       "      <td>0.749741</td>\n",
       "      <td>0.600509</td>\n",
       "      <td>0.851916</td>\n",
       "      <td>0.726213</td>\n",
       "      <td>0.471879</td>\n",
       "      <td>0.419848</td>\n",
       "      <td>DeepLocAAindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.752795</td>\n",
       "      <td>0.722854</td>\n",
       "      <td>0.559796</td>\n",
       "      <td>0.834495</td>\n",
       "      <td>0.697146</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.413129</td>\n",
       "      <td>DeepLocAAindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.818093</td>\n",
       "      <td>0.761117</td>\n",
       "      <td>0.585242</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.733387</td>\n",
       "      <td>0.496522</td>\n",
       "      <td>0.480465</td>\n",
       "      <td>DeepLocAAindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.802143</td>\n",
       "      <td>0.752844</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>0.803136</td>\n",
       "      <td>0.741263</td>\n",
       "      <td>0.485245</td>\n",
       "      <td>0.410101</td>\n",
       "      <td>DeepLocAutocorr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.721729</td>\n",
       "      <td>0.690796</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.803136</td>\n",
       "      <td>0.664927</td>\n",
       "      <td>0.344307</td>\n",
       "      <td>0.433009</td>\n",
       "      <td>DeepLocAutocorr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMClassifier</th>\n",
       "      <td>0.427408</td>\n",
       "      <td>0.593588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674078</td>\n",
       "      <td>DeepLocAutocorr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNClassifier</th>\n",
       "      <td>0.767444</td>\n",
       "      <td>0.726991</td>\n",
       "      <td>0.582697</td>\n",
       "      <td>0.825784</td>\n",
       "      <td>0.704241</td>\n",
       "      <td>0.423463</td>\n",
       "      <td>0.471754</td>\n",
       "      <td>DeepLocAutocorr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auc       acc       sen       spe       bac  \\\n",
       "LGBMClassifier          0.817330  0.754912  0.605598  0.857143  0.731370   \n",
       "RandomForestClassifier  0.785683  0.749741  0.600509  0.851916  0.726213   \n",
       "SVMClassifier           0.752795  0.722854  0.559796  0.834495  0.697146   \n",
       "NNClassifier            0.818093  0.761117  0.585242  0.881533  0.733387   \n",
       "LGBMClassifier          0.802143  0.752844  0.679389  0.803136  0.741263   \n",
       "RandomForestClassifier  0.721729  0.690796  0.526718  0.803136  0.664927   \n",
       "SVMClassifier           0.427408  0.593588  0.000000  1.000000  0.500000   \n",
       "NNClassifier            0.767444  0.726991  0.582697  0.825784  0.704241   \n",
       "\n",
       "                             mcc    cutoff             data  \n",
       "LGBMClassifier          0.483018  0.429081   DeepLocAAindex  \n",
       "RandomForestClassifier  0.471879  0.419848   DeepLocAAindex  \n",
       "SVMClassifier           0.413228  0.413129   DeepLocAAindex  \n",
       "NNClassifier            0.496522  0.480465   DeepLocAAindex  \n",
       "LGBMClassifier          0.485245  0.410101  DeepLocAutocorr  \n",
       "RandomForestClassifier  0.344307  0.433009  DeepLocAutocorr  \n",
       "SVMClassifier           0.000000  0.674078  DeepLocAutocorr  \n",
       "NNClassifier            0.423463  0.471754  DeepLocAutocorr  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.concat(df_results)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('../results/summary/DSCDeepLoc.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3e12de8d4f511a3f40a134d20c84f219b709a35adcae8dcc2b376a736afcf2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('bioenv_ver0.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
